import pandas as pd
import numpy as np
import joblib
import optuna
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import TimeSeriesSplit
from preprocessing import load_and_merge

def objective(trial, X, y):
    """
    Optunaê°€ ê° Trialë§ˆë‹¤ í˜¸ì¶œí•˜ì—¬, ì£¼ì–´ì§„ íŒŒë¼ë¯¸í„°ë¡œ CV RMSEë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜.
    - trial: Optuna trial ê°ì²´
    - X: í”¼ì²˜(ì„¤ëª… ë³€ìˆ˜) DataFrame
    - y: íƒ€ê¹ƒ(ì¢…ì† ë³€ìˆ˜) Series
    """
    # 1) íƒìƒ‰í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³µê°„ ì •ì˜
    param = {
        'num_leaves': trial.suggest_int('num_leaves', 16, 256),
        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'max_depth': trial.suggest_int('max_depth', 5, 30),
        # ì¶”ê°€ì ìœ¼ë¡œ ìœ ìš©í•œ íŒŒë¼ë¯¸í„°ë¥¼ ë” íƒìƒ‰í•˜ë„ë¡ í¬í•¨í•  ìˆ˜ ìˆìŒ
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)
    }

    # 2) ì‹œê³„ì—´ êµì°¨ê²€ì¦ ë¶„í• ê¸° ì„¤ì • (max_train_size ë¯¸ì‚¬ìš© â†’ í™•ì¥í˜• ìœˆë„ìš°)
    tss = TimeSeriesSplit(n_splits=5)

    rmses = []
    for train_idx, valid_idx in tss.split(X):
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]

        # 3) ëª¨ë¸ í•™ìŠµ (CV ë‚´ ê²€ì¦ìš© eval_setì€ ì œê±°)
        model = LGBMRegressor(**param, random_state=42, verbose=-1)
        model.fit(X_train, y_train)

        # 4) ê²€ì¦ ì„¸íŠ¸ ì˜ˆì¸¡ â†’ RMSE ê³„ì‚°
        preds = model.predict(X_valid)
        rmses.append(mean_squared_error(y_valid, preds) ** 0.5)

    # 5) ë‹¤ì„¯ ê°œ Fold RMSE í‰ê·  ë°˜í™˜
    return np.mean(rmses)


def optimize_target(target_name, X, y):
    """
    íŠ¹ì • íƒ€ê¹ƒ(target_name)ì— ëŒ€í•´ Optuna Studyë¥¼ ìƒì„±í•˜ê³  ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰ í›„ ëª¨ë¸ ì €ì¥
    - target_name: íƒ€ê¹ƒ ì»¬ëŸ¼ëª… (ë¬¸ìì—´)
    - X: í”¼ì²˜ DataFrame
    - y: íƒ€ê¹ƒ Series
    """
    # 1) Optuna Study ìƒì„±
    study = optuna.create_study(direction='minimize')
    study.optimize(lambda trial: objective(trial, X, y), n_trials=50)

    # 2) ìµœì  íŒŒë¼ë¯¸í„° ë° CV RMSE ì¶œë ¥
    best_params = study.best_params
    best_rmse = study.best_value
    print(f"\nğŸ” [{target_name}] ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
    print(f"ğŸ” [{target_name}] CV RMSE (í‰ê· ): {best_rmse:.4f}")

    # 3) ìµœì  ëª¨ë¸ í•™ìŠµ & ì €ì¥
    best_model = LGBMRegressor(**best_params, random_state=42)
    best_model.fit(X, y)  # ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ìµœì¢… í•™ìŠµ
    model_path = f"models/model_{target_name}_optuna.pkl"
    joblib.dump(best_model, model_path)
    print(f"âœ… [{target_name}] ìµœì  ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")


def main():
    # 1) ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    forecast_path = 'data/ë°ì´í„°_ë¶„ì„ê³¼ì œ_7_ê¸°ìƒì˜ˆì¸¡ë°ì´í„°_2401_2503.csv'
    observed_path = 'data/ë°ì´í„°_ë¶„ì„ê³¼ì œ_7_ê¸°ìƒê´€ì¸¡ë°ì´í„°_2401_2503.csv'
    merged_df = load_and_merge(forecast_path, observed_path)

    # 2) í”¼ì²˜ & ê° íƒ€ê¹ƒ ë¶„ë¦¬ (ì‹œê°„ íŒŒìƒ + êµí˜¸ì‘ìš© í¬í•¨ ì™„ë£Œëœ ìƒíƒœ)
    features = [
        'ì¼ì‚¬ëŸ‰(w/m^2)_ì˜ˆì¸¡',
        'ìŠµë„(%)_ì˜ˆì¸¡',
        'ì ˆëŒ€ìŠµë„_ì˜ˆì¸¡',
        'ê¸°ì˜¨(degC)_ì˜ˆì¸¡',
        'ëŒ€ê¸°ì••(mmHg)_ì˜ˆì¸¡',
        'hour', 
        'month', 
        'weekday',
        'ì¼ì‚¬ëŸ‰xê¸°ì˜¨', 
        'ìŠµë„xê¸°ì˜¨', 
        'ì¼ì‚¬ëŸ‰xì ˆëŒ€ìŠµë„'
    ]
    X = merged_df[features]
    targets = {
        'ìŠµë„(%)_ê´€ì¸¡': merged_df['ìŠµë„(%)_ê´€ì¸¡'],
        'ê¸°ì˜¨(degC)_ê´€ì¸¡': merged_df['ê¸°ì˜¨(degC)_ê´€ì¸¡'],
        'ëŒ€ê¸°ì••(mmHg)_ê´€ì¸¡': merged_df['ëŒ€ê¸°ì••(mmHg)_ê´€ì¸¡']
    }

    # 3) íƒ€ê¹ƒë³„ ìµœì í™” ë°˜ë³µ
    for target_name, y in targets.items():
        print(f"\n========== [{target_name}] ìµœì í™” ì‹œì‘ ==========")
        optimize_target(target_name, X, y)


if __name__ == "__main__":
    main()