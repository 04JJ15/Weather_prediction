## 1. 프로젝트 개요
- **과제명:** 기상 예측 지점–관측 지점 오차 보정 회귀모델 개발  
- **목표:** 예측값으로 실제 관측값(습도·기온·대기압) 보정 → MAE/RMSE 최소화  
- **평가 지표:** 가중치(습도 0.3 · 기온 0.5 · 대기압 0.2) 적용한 RMSE/MAE  

## 2. 프로젝트 구조
```plaintext
weather_prediction_project/
├── data/                   # 원본·병합 CSV
├── models/                 # 학습된 모델(.pkl)
├── src/
│   ├── preprocessing.py    # load_and_merge() + 단위 통일
│   ├── train.py            # LightGBM 학습 및 저장
│   └── evaluate.py         # 모델 평가 및 가중 점수 계산
└── main.py                 # EDA (병합 확인·통계·이상치·상관관계)
```

## 3. 수행 계획
1. **환경 구성** (VSCode, 필수 라이브러리 설치)  
2. **데이터 준비** (`data/`에 예측·관측 CSV 배치)  
3. **전처리** (`src/preprocessing.py`): 시간 병합 + 대기압 단위 통일  
4. **병합 확인 & CSV 저장** (`main.py`)  
5. **EDA: 결측치·기초 통계·이상치 점검** (`main.py`)  
6. **변수별 통계 해석** (`main.py`)  
7. **Feature/Target 분리** (`main.py`)  
8. **상관관계 히트맵 시각화** (`main.py`)  
9. **베이스라인 모델 학습** (`src/train.py`): LightGBM 학습 & 저장  
10. **모델 평가 & 가중 점수 계산** (`src/evaluate.py`)

## 4. 주요 EDA 결과
- **결측치:** 없음  
- **기초 통계:**  
  - **일사량:** 절반 이상 0 → 시간·계절 변수 필요  
  - **절대습도:** 분산 작음 → 기여도 검토  
  - **기온:** 음수 포함(동절기) → 계절별 보정 필요  
  - **대기압:** 단위 통일(hPa→mmHg) 완료  
- **이상치:** 물리적 타당 → 유지

## 5. 피처 & 타겟
```python
features = [
    '일사량(w/m^2)_예측',
    '습도(%)_예측',
    '절대습도_예측',
    '기온(degC)_예측',
    '대기압(mmHg)_예측'
]
targets = [
    '습도(%)_관측',
    '기온(degC)_관측',
    '대기압(mmHg)_관측'
]
```

# 🎯 공모전 과제 목표 다시 확인

- **예측 지점의 기상 데이터** → **실제 관측 지점 데이터 간 오차를 보정**
- 입력값(예측 데이터)을 기반으로 **정확한 관측값(습도, 기온, 대기압)**을 예측
- **평가 기준**: MAE, RMSE, 가중 평균 오차  
  - 가중치: 습도 0.3, 기온 0.5, 대기압 0.2

---

## 🤔 어떤 회귀 모델이 적절할까?

| 모델명 | 특징 | 장점 | 단점 | 공모전 적합성 |
|--------|------|------|------|----------------|
| Linear Regression | 선형 모델 | 빠르고 해석 용이 | 복잡한 관계 못 잡음 | 🔸 (베이스라인용) |
| Ridge/Lasso | 규제가 있는 선형 모델 | 과적합 억제 | 하이퍼파라미터 필요 | 🔸 |
| Random Forest Regressor | 앙상블 결정트리 | 비선형 관계 학습, 해석 가능 | 느리고 메모리 사용 큼 | ✅ |
| XGBoost | 부스팅 기반 트리 모델 | 강력한 성능, 결측치 자동 처리 | 복잡하고 튜닝 필요 | ✅ |
| LightGBM | XGBoost보다 빠름 | 빠르고 효율적 | 분포 균형에 민감 | ✅✅ |

---

## ✅ 가장 적절한 모델: LightGBM or XGBoost

### 이유:
- 데이터는 수천 건 규모 → **트리 기반 모델**에 적합
- 입력값과 출력값 간 관계가 **비선형적임** (특히 기온, 일사량 등)
- 평가 지표로 **RMSE/MAE**를 사용 → 트리 기반 회귀 모델이 강점
- **다중 출력 회귀**도 지원하거나, 각 변수별로 **개별 모델링** 가능

---

## 🏁 추천 전략

### 베이스라인:
- **LightGBM Regressor**로 각 target(기온, 습도, 대기압)을 **별도 학습**
- 이후 결과를 조합하여 **가중합 평가**


## 6. 10단계 평가 결과
| Target               | MAE    | RMSE   | 가중 점수 |
|----------------------|--------|--------|-----------|
| 습도(%)_관측         | 5.9097 | 7.7887 | 2.0548    |
| 기온(degC)_관측      | 0.9673 | 1.2514 | 0.5547    |
| 대기압(mmHg)_관측    | 0.3666 | 0.4777 | 0.0844    |
| **최종 스코어**      |        |        | **2.6939** |

## 7. 11단계 결과 비교: 시간 파생 변수 도입 전·후

아래 표는 **10단계(시간 파생 변수 도입 전)**와 **11단계(도입 후)**의 MAE·RMSE 및 가중 점수를 나란히 비교한 것입니다.

| Target               | 단계 | MAE    | RMSE   | (MAE+RMSE)/2 | 가중치 | 가중 점수 |
|----------------------|------|--------|--------|--------------|--------|-----------|
| **습도(%)_관측**     | 10   | 5.9097 | 7.7887 | 6.8492       | 0.3    | 2.0548    |
|                      | 11   | 4.7764 | 6.3366 | 5.5565       | 0.3    | 1.6669    |
| **기온(degC)_관측**  | 10   | 0.9673 | 1.2514 | 1.1094       | 0.5    | 0.5547    |
|                      | 11   | 0.8152 | 1.0564 | 0.9358       | 0.5    | 0.4679    |
| **대기압(mmHg)_관측**| 10   | 0.3666 | 0.4777 | 0.4222       | 0.2    | 0.0844    |
|                      | 11   | 0.3055 | 0.4007 | 0.3531       | 0.2    | 0.0706    |
| **최종 스코어**      | 10   | —      | —      | —            | —      | **2.6939**|
|                      | 11   | —      | —      | —            | —      | **2.2055**|

### 1. 습도(%)_관측
- **MAE:** 5.9097 → 4.7764 (↓1.1333)  
- **RMSE:** 7.7887 → 6.3366 (↓1.4521)  
- **가중 점수:** 2.0548 → 1.6669 (↓0.3879)

💡 시간 파생 변수를 통해 “특정 시간대에 습도가 어떻게 변화하는가” 정보를 모델이 학습할 수 있어,  
절반 이상이 0인 일사량과 함께 시간대 신호가 습도 보정에 유의미하게 기여했습니다.

---

### 2. 기온(degC)_관측
- **MAE:** 0.9673 → 0.8152 (↓0.1521)  
- **RMSE:** 1.2514 → 1.0564 (↓0.1950)  
- **가중 점수:** 0.5547 → 0.4679 (↓0.0868)

💡 하루 중 기온 변화 패턴(아침 vs 한낮 vs 저녁) 정보를 추가함으로써,  
특히 낮과 밤의 온도 차이를 더 정확하게 보정할 수 있었습니다.

---

### 3. 대기압(mmHg)_관측
- **MAE:** 0.3666 → 0.3055 (↓0.0611)  
- **RMSE:** 0.4777 → 0.4007 (↓0.0770)  
- **가중 점수:** 0.0844 → 0.0706 (↓0.0138)

💡 대기압도 시간대별 변동이 존재하므로, 단위 통일 후 시간 정보를 반영하면 오차가 줄어듭니다.

---

### 4. 최종 가중 평균 점수
- **도입 전:** 2.6939  
- **도입 후:** 2.2055 (↓0.4884)  

> **결론:**  
> 시간 파생 변수를 추가하여 모든 타깃에서 MAE와 RMSE가 감소했고,  
> 공모전의 가중 평균 점수도 약 0.49 포인트 개선되었습니다.  
> 이는 기상 데이터의 “시간·계절 패턴”을 반영했을 때 오차 보정 효과가 상당함을 의미합니다.


## 11단계 이어서 진행 계획

### 앞서 완료한 1단계
- **시간 파생 변수 추가**  
  `src/preprocessing.py` 에서 `hour`, `month`, `weekday` 피처를 생성하고  
  이를 기반으로 모델을 재학습·재평가하여 성능(가중 평균 점수)이 2.6939 → 2.2055로 개선됨.

---

## 2단계: 교호작용(Interaction) 피처 생성

1. **왜 하는가?**  
   - 두 개 이상의 변수가 함께 작용할 때 생기는 효과(예: “일사량과 기온이 동시에 높으면 실제 관측 기온이 더 크게 오차” 같은 패턴)를 잡아내기 위해  
   - 단일 피처만 넣을 때보다, 변수 곱(또는 비율 등)으로 새로운 차원을 모델에 제공하면 예측력이 올라갈 수 있음.

2. **어떤 피처를 만들까?**  
   ```python
   # 예시 가능한 교호작용
   merged['일사량×기온']      = merged['일사량(w/m^2)_예측'] * merged['기온(degC)_예측']
   merged['습도×기온']       = merged['습도(%)_예측'] * merged['기온(degC)_예측']
   merged['일사량×절대습도']  = merged['일사량(w/m^2)_예측'] * merged['절대습도_예측']
   # 필요에 따라 추가
  

---

## 11-2 단계 결과 비교: 상호작용 피처 도입 전·후

아래 표는 **10단계(기본 피처만)**, **11-1단계(시간 파생 변수 추가)**, **11-2단계(시간 파생 + 상호작용 피처)**의 MAE·RMSE 및 가중 점수를 나란히 비교한 것입니다.

| Target               | 단계   | MAE    | RMSE   | (MAE+RMSE)/2 | 가중치 | 가중 점수 |
|----------------------|--------|--------|--------|--------------|--------|-----------|
| **습도(%)_관측**     | 10     | 5.9097 | 7.7887 | 6.8492       | 0.3    | 2.0548    |
|                      | 11-1   | 4.7764 | 6.3366 | 5.5565       | 0.3    | 1.6669    |
|                      | 11-2   | 4.7195 | 6.2527 | 5.4861       | 0.3    | 1.6458    |
| **기온(degC)_관측**  | 10     | 0.9673 | 1.2514 | 1.1094       | 0.5    | 0.5547    |
|                      | 11-1   | 0.8152 | 1.0564 | 0.9358       | 0.5    | 0.4679    |
|                      | 11-2   | 0.8111 | 1.0495 | 0.9303       | 0.5    | 0.4652    |
| **대기압(mmHg)_관측**| 10     | 0.3666 | 0.4777 | 0.4222       | 0.2    | 0.0844    |
|                      | 11-1   | 0.3055 | 0.4007 | 0.3531       | 0.2    | 0.0706    |
|                      | 11-2   | 0.3025 | 0.3974 | 0.3499       | 0.2    | 0.0700    |
| **최종 스코어**      | 10     |        |        |              |        | **2.6939**|
|                      | 11-1   |        |        |              |        | **2.2055**|
|                      | 11-2   |        |        |              |        | **2.1810**|

---

### 1. 습도(%)_관측
- **10단계:** MAE 5.9097 → **11-1:** MAE 4.7764 (↓1.1333) → **11-2:** MAE 4.7195 (↓0.0569)  
- **10단계:** RMSE 7.7887 → **11-1:** RMSE 6.3366 (↓1.4521) → **11-2:** RMSE 6.2527 (↓0.0839)  
- 가중 점수: 2.0548 → **11-1:** 1.6669 (↓0.3879) → **11-2:** 1.6458 (↓0.0211)  

> 상호작용 피처(일사량×기온 등)를 추가하자, 습도 오차가 소폭 더 감소했습니다.  
> “일사량과 기온이 동시에 높을 때의 습도 패턴” 같은 비선형 정보를 일부 캡처한 효과로 보입니다.

---

### 2. 기온(degC)_관측
- **10단계:** MAE 0.9673 → **11-1:** 0.8152 (↓0.1521) → **11-2:** 0.8111 (↓0.0041)  
- **10단계:** RMSE 1.2514 → **11-1:** 1.0564 (↓0.1950) → **11-2:** 1.0495 (↓0.0069)  
- 가중 점수: 0.5547 → **11-1:** 0.4679 (↓0.0868) → **11-2:** 0.4652 (↓0.0027)  

> 기온에 대해서도 상호작용 피처는 추가적인 미세 개선을 제공했습니다.  
> 주로 “습도×기온” 조합이 낮과 밤의 복합 영향 등을 보정했을 것으로 추정됩니다.

---

### 3. 대기압(mmHg)_관측
- **10단계:** MAE 0.3666 → **11-1:** 0.3055 (↓0.0611) → **11-2:** 0.3025 (↓0.0030)  
- **10단계:** RMSE 0.4777 → **11-1:** 0.4007 (↓0.0770) → **11-2:** 0.3974 (↓0.0033)  
- 가중 점수: 0.0844 → **11-1:** 0.0706 (↓0.0138) → **11-2:** 0.0700 (↓0.0006)  

> 대기압에서도 상호작용 피처의 효과는 소폭이나마 확인됩니다.  
> 시간 파생 변수 도입으로 이미 많이 개선된 상태에서, 교호작용이 조금 더 미세 조정을 해준 모습입니다.

---

### 4. 최종 가중 평균 점수
- **10단계:** 2.6939  
- **11-1:** 2.2055 (↓0.4884)  
- **11-2:** 2.1810 (↓0.0245)  

> **요약:**  
> 1) 시간 파생 변수를 추가한 후(11-1) 모델 성능이 크게 개선되었고,  
> 2) 상호작용 피처를 추가한 후(11-2)에도 **소폭 추가 개선**이 이루어졌습니다.  
> 즉, 교호작용 피처는 이미 반영된 시간·계절 정보를 보완하는 역할로, 특히 습도와 기온 오차를 더 줄여주었습니다.

---

## 결론
- **주요 성능 향상 요인:**  
  1. **시간 파생 변수** 추가(하루·계절 패턴 캡처)  
  2. **교호작용 피처** 추가(변수 간 상호 영향 보정)  

- **다음 단계:**  
  1. 하이퍼파라미터 튜닝 → 추가 성능 개선 여부 확인  
  2. 교차검증 도입 → 일반화 성능 점검  
  3. 모델 앙상블 → 최종 성능 안정화 및 향상

## 11-3 하이퍼파라미터 튜닝

### 왜 하는가?
- 기본 LightGBM 기본 설정(파라미터 기본값)만으로는 **각 타깃마다 최적의 성능을 내기 어렵습니다**.  
- `num_leaves`, `learning_rate`, `n_estimators`, `max_depth` 등 주요 파라미터를 조정하면  
  - 모델이 데이터의 복잡한 패턴을 더 잘 학습하고  
  - **MAE/RMSE를 추가로 낮출 수 있습니다**.  
- 또한, 단일 학습이 아닌 **교차검증**과 결합하면 과적합 위험을 줄이며, 일반화 성능을 더 객관적으로 평가할 수 있습니다.

---

### 어떻게 진행할까?
1. **GridSearchCV + TimeSeriesSplit** 사용  
   - `TimeSeriesSplit`을 이용해 시계열 순서를 유지하며 훈련/검증 분할  
   - `GridSearchCV`로 미리 정의한 파라미터 그리드를 순차적으로 탐색  
   - 평가는 RMSE(`neg_root_mean_squared_error`) 기준  

2. **train.py 수정 방법**  
   - 기존 `LGBMRegressor.fit(X, y[col])` 부분을 `GridSearchCV`로 교체  
   - 최적의 파라미터가 발견된 모델을 `models/` 폴더에 저장  
   - 탐색 범위 예시:  
     ```python
     param_grid = {
       'num_leaves': [31, 63],
       'learning_rate': [0.1, 0.01],
       'n_estimators': [100, 300],
       'max_depth': [ -1, 10, 20 ]
     }
     ```

# 하이퍼파라미터 튜닝 결과 해석 및 보충 제안

아래는 11-3단계(하이퍼파라미터 튜닝 + 교차검증) 결과입니다.  
각 타깃별로 “교차검증 평균 RMSE(CV RMSE)”와 “전체 데이터에 대해 재학습한 후의 MAE·RMSE”를 함께 보여줍니다.

---

## 결과 요약

### [습도(%)_관측]
- **최적 파라미터**:
  ```python
  {
    'learning_rate': 0.01,
    'max_depth': 10,
    'n_estimators': 300,
    'num_leaves': 31
  }
  ```
- **CV RMSE (평균)**: 11.2447  
- **전체 데이터 MAE**: 6.3167  
- **전체 데이터 RMSE**: 8.1586

---

### [기온(degC)_관측]
- **최적 파라미터**:
  ```python
  {
    'learning_rate': 0.1,
    'max_depth': -1,
    'n_estimators': 100,
    'num_leaves': 63
  }
  ```
- **CV RMSE (평균)**: 2.9481  
- **전체 데이터 MAE**: 0.6452  
- **전체 데이터 RMSE**: 0.8357

---

### [대기압(mmHg)_관측]
- **최적 파라미터**:
  ```python
  {
    'learning_rate': 0.1,
    'max_depth': 10,
    'n_estimators': 100,
    'num_leaves': 31
  }
  ```
- **CV RMSE (평균)**: 0.9205  
- **전체 데이터 MAE**: 0.3012  
- **전체 데이터 RMSE**: 0.3960

---

## 1. CV RMSE vs 전체 데이터 RMSE 차이

- **CV RMSE**  
  - GridSearchCV 내부에서 `TimeSeriesSplit(n_splits=3)`을 이용하여 “과거 → 미래” 순서로 3번 검증  
  - 각 fold에서 나온 RMSE 평균 → **실제 모델 일반화 성능 지표**

- **전체 데이터 RMSE**  
  - 최적 파라미터로 전체 데이터를 재학습 후, 같은 데이터에 대해 예측  
  - **과적합 가능성** 존재 → 일반화 성능과 다를 수 있음

---

## 2. 타깃별 상세 해석

### ① 습도(%)_관측

- 학습이 느린 `learning_rate=0.01`과 `n_estimators=300` 조합
- `max_depth=10`, `num_leaves=31` → 과적합 방지 시도
- **CV RMSE: 11.2447**
  - 이전 학습 세트 RMSE(~6.34)보다 큼
  - 미래 데이터 예측 상황을 더 정확히 반영
- **전체 데이터 RMSE: 8.1586**
  - 학습 세트를 그대로 다시 예측한 값 → CV보다 작게 나옴

**결론**  
CV RMSE(11.24)를 모델 성능 판단 기준으로 삼는 것이 안전

---

### ② 기온(degC)_관측

- `learning_rate=0.1`과 `n_estimators=100` → 빠른 학습
- `max_depth=-1`, `num_leaves=63` → 복잡한 트리
- **CV RMSE: 2.9481**
  - 이전 RMSE(~1.06)보다 큼 → 계절 불일치 가능성
- **전체 데이터 RMSE: 0.8357**

**결론**  
CV RMSE(2.95)가 실제 예측 시 오차에 더 가까움  
→ 기온 예측 성능 개선 필요 (목표 RMSE: 1~1.5도 이내)

---

### ③ 대기압(mmHg)_관측

- `learning_rate=0.1`, `n_estimators=100` → 적절한 설정
- `max_depth=10`, `num_leaves=31`
- **CV RMSE: 0.9205**
  - 학습 세트 RMSE(~0.40)의 두 배 이상
- **전체 데이터 RMSE: 0.3960**

**결론**  
CV RMSE(0.92)는 목표 수준에 가까움  
→ 모델 안정성 양호하나, 분할 방식에 따른 오차 주의

---

## 3. 보충 및 개선 방안

### (1) CV RMSE와 학습 세트 RMSE 차이 원인

- **계절 분포 불균형**: TimeSeriesSplit 분할 시 특정 계절 데이터에 치우침
- **데이터 분포 변화**: 특정 시기 급변(예: 겨울철) 구간에 취약
- **모델 복잡도 불균형**: 일부 fold에서 과적합/과소적합 동시 발생 가능

---

### (2) 개선 방향

#### a. TimeSeriesSplit 설정 변경
- `n_splits=5`로 증가 → 계절 편향 완화
- `max_train_size` 지정 예시:
  ```python
  TimeSeriesSplit(n_splits=5, max_train_size=2000)
  ```

#### b. 파라미터 그리드 확장
```python
param_grid = {
    'num_leaves': [15, 31, 63, 127],
    'learning_rate': [0.2, 0.1, 0.05, 0.01],
    'n_estimators': [50, 100, 200, 300, 500],
    'max_depth': [-1, 5, 10, 15]
}
```

- 먼저 큰 스텝으로 → 이후 세분화

#### c. Optuna 활용 (자동 튜닝)
```python
import optuna

def objective(trial):
    param = {
        'num_leaves': trial.suggest_int('num_leaves', 16, 128),
        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'max_depth': trial.suggest_int('max_depth', 5, 20)
    }
    model = LGBMRegressor(**param, random_state=42)
    rmses = []
    for train_idx, val_idx in TimeSeriesSplit(n_splits=3).split(X):
        model.fit(X.iloc[train_idx], y[col].iloc[train_idx])
        preds = model.predict(X.iloc[val_idx])
        rmses.append(mean_squared_error(y[col].iloc[val_idx], preds)**0.5)
    return np.mean(rmses)

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)
print(study.best_params)
```

---

#### d. 피처 엔지니어링 보강

- 새로운 파생 변수 생성 (예: 최고–최저 기온 차이)
- 로그/차분/스케일링 등 비선형 처리

#### e. 앙상블 및 스태킹 적용

- XGBoost, RandomForest, CatBoost 등과 앙상블
- 스태킹 예시:
  - 1차 모델 예측 → 메타 모델로 입력

---

## 4. 요약 제안

- CV RMSE는 실제 예측 오차를 반영 → 이를 기준으로 판단
- TimeSeriesSplit 구조 조정 필요
- 파라미터 튜닝 고도화(Optuna), 피처 엔지니어링, 앙상블 등을 통한 성능 개선
- 반복적인 실험으로 가중 평균 RMSE 점수를 꾸준히 줄여나가는 전략 권장

## 11-2 ~ 11-3.3 단계별 결과 비교 및 해석

아래 표는 **11-2(시간·교호작용만 적용), 11-3.1(3-split CV+소규모 그리드), 11-3.2(5-split CV+확장 그리드), 11-3.3(Optuna 튜닝+5-split CV)** 네 가지 단계별로 주요 지표를 정리한 것입니다.  
- 11-2에서는 교차검증(CV)을 적용하지 않았으므로 “CV RMSE”가 없고, **전체 데이터에 대해 재학습 후** 얻은 MAE·RMSE(=Full-Train 지표)만 표기했습니다.  
- 11-3.1/11-3.2에서는 “CV RMSE”와 “Full-Train MAE·RMSE”를 모두 기록했습니다.  
- 11-3.3(Optuna)에서는 “CV RMSE(평균)”만 제공되었으므로, 나머지 칸은 빈칸으로 두었습니다.

| Target               | 단계    | CV RMSE | Full-Train MAE | Full-Train RMSE |
|----------------------|---------|---------|----------------|-----------------|
| **습도(%)_관측**     | 11-2    | –       | 4.7195         | 6.2527          |
|                      | 11-3.1  | 11.2447 | 6.3167         | 8.1586          |
|                      | 11-3.2  | 11.3202 | 6.8986         | 8.8745          |
|                      | 11-3.3  | 11.1544 | –              | –               |
| **기온(degC)_관측**  | 11-2    | –       | 0.8111         | 1.0495          |
|                      | 11-3.1  | 2.9481  | 0.6452         | 0.8357          |
|                      | 11-3.2  | 2.9007  | 0.5469         | 0.7183          |
|                      | 11-3.3  | 2.8588  | –              | –               |
| **대기압(mmHg)_관측**| 11-2    | –       | 0.3025         | 0.3974          |
|                      | 11-3.1  | 0.9205  | 0.3012         | 0.3960          |
|                      | 11-3.2  | 0.8882  | 0.3309         | 0.4354          |
|                      | 11-3.3  | 0.9045  | –              | –               |

---

### 1. 습도(%)_관측

- **11-2 (시간·교호작용)**  
  - Full-Train RMSE: **6.2527**  
  - CV를 도입하지 않았으므로 실제 일반화 성능을 알기 어려움.

- **11-3.1 (3-split CV + 소규모 그리드)**  
  - CV RMSE: **11.2447**  
  - Full-Train RMSE: **8.1586**  
  - CV RMSE ≫ Full-Train RMSE → 과거→미래 예측 시 오차가 크게 벌어지는 상황

- **11-3.2 (5-split CV + 확장 그리드)**  
  - CV RMSE: **11.3202** (11-3.1보다 소폭 상승)  
  - Full-Train RMSE: **8.8745** (11-3.1보다 상승)  
  - 그리드를 확장했지만, 최적 파라미터가 더 단순화되어(예: `num_leaves=15`) 학습 지표가 악화된 모습 → 일반화는 거의 개선되지 않음

- **11-3.3 (Optuna 튜닝 + 5-split CV)**  
  - CV RMSE: **11.1544** (11-3.2 대비 소폭 하락)  
  - 최적 파라미터:  
    ```python
    {
      'num_leaves': 196,
      'learning_rate': 0.0383,
      'n_estimators': 84,
      'max_depth': 28,
      'min_child_samples': 62,
      'subsample': 0.7940,
      'colsample_bytree': 0.5038
    }
    ```
  - GridSearch로 찾은 파라미터보다 CV RMSE가 약간 개선되었으나, **전반적으로 11~11.3** 정도로 큰 차이는 없음  
  - 여전히 “실제 미래 예측 오차”는 **약 11.15** 수준

> **해석:**  
> - 11-2→11-3.1 사이에 “CV를 도입하며” 일반화 성능이 대폭 악화(Full-Train 6.25→8.16, CV 11.24로 급등)  
> - 11-3.1→11-3.2에서 “그리드 확장”을 했지만 최적 파라미터가 오히려 단순해지면서 Full-Train도 나빠졌다(8.16→8.87).  
> - 11-3.3 Optuna 튜닝으로 소폭 CV RMSE가 **11.32→11.15**로 개선되었으나,  
>   - 여전히 **CV RMSE ≈ 11.2** 수준으로 “습도 예측 오차”가 매우 크다는 점이 명확히 드러남  
> - 이 단계까지 진행해도 “습도” 모델의 일반화 오차가 너무 크므로,  
>   - **추가 피처(예: 이슬점 계산, 풍속 등)를 포함하거나**,  
>   - **다른 모델(예: RandomForest, CatBoost) 앙상블**,  
>   - 또는 **更多의 데이터(외부 날씨 지표)** 필요성이 높음

---

### 2. 기온(degC)_관측

- **11-2 (시간·교호작용)**  
  - Full-Train RMSE: **1.0495**  
  - (CV 적용 전)

- **11-3.1 (3-split CV + 소규모 그리드)**  
  - CV RMSE: **2.9481**  
  - Full-Train RMSE: **0.8357**  
  - CV RMSE ≫ Full-Train RMSE → 과거→미래 예측 시 오차가 약 2.95도

- **11-3.2 (5-split CV + 확장 그리드)**  
  - CV RMSE: **2.9007** (소폭 개선)  
  - Full-Train RMSE: **0.7183** (개선)  
  - “더 복잡한 모델(예: `num_leaves=127, max_depth=10`)”이 전체 학습 시 오차를 확 줄였으며,  
    CV RMSE도 2.95→2.90로 개선됨

- **11-3.3 (Optuna 튜닝 + 5-split CV)**  
  - CV RMSE: **2.8588** (11-3.2 대비 추가 개선)  
  - 최적 파라미터:  
    ```python
    {
      'num_leaves': 58,
      'learning_rate': 0.0442,
      'n_estimators': 265,
      'max_depth': 7,
      'min_child_samples': 12,
      'subsample': 0.5704,
      'colsample_bytree': 0.9660
    }
    ```
  - GridSearch보다 훨씬 세밀하게 탐색하여, “CV RMSE 2.90→2.86”로 추가 하락

> **해석:**  
> - **11-2** 대비 **11-3.1**에서 CV RMSE가 크게 증가(1.05→2.95)했지만,  
>   11-3.2에서 그리드 확장으로 다시 Full-Train RMSE를 0.83→0.72로 낮추고, CV RMSE 2.95→2.90로 점진 개선  
> - **11-3.3 Optuna**로 “모델 복잡도, 부스팅 개수, 샘플링 비율” 등을 더 세밀하게 조정해 **CV RMSE 2.90→2.86** 달성  
> - 결론적으로, 기온 모델은  
>   - **11-3.1 → 11-3.3** 구간에서 CV RMSE를 약 **2.95 → 2.86**로 개선  
>   - CV RMSE ≈ **2.86**는 “학습 세트(Full-Train RMSE 0.72)”보다 상당히 높은 수치지만,  
>     과거→미래 예측 오차로 보면 **이 정도 성능이 현실적인 한계**로 보임  
> - 다음 단계:  
>   - **시차( lag ) 피처**(예: 이전 시점 기온, 이동평균) 추가하거나,  
>   - **앙상블(예: LightGBM+CatBoost)** 시도 → CV RMSE 2.8 이하 도전

---

### 3. 대기압(mmHg)_관측

- **11-2 (시간·교호작용)**  
  - Full-Train RMSE: **0.3974**

- **11-3.1 (3-split CV + 소규모 그리드)**  
  - CV RMSE: **0.9205**  
  - Full-Train RMSE: **0.3960**  
  - CV RMSE ≈ **0.92**

- **11-3.2 (5-split CV + 확장 그리드)**  
  - CV RMSE: **0.8882** (11-3.1 대비 개선)  
  - Full-Train RMSE: **0.4354** (악화)  
  - “과소적합” 경향: `num_leaves=15` 같은 단순 모델

- **11-3.3 (Optuna 튜닝 + 5-split CV)**  
  - CV RMSE: **0.9045** (11-3.2 대비 소폭 악화)  
  - 최적 파라미터:  
    ```python
    {
      'num_leaves': 25,
      'learning_rate': 0.0572,
      'n_estimators': 434,
      'max_depth': 14,
      'min_child_samples': 21,
      'subsample': 0.6302,
      'colsample_bytree': 0.9594
    }
    ```
  - Optuna가 탐색 과정 중 “약간 과소적합→약간 과적합” 구간을 오가며 평균을 취한 모습

> **해석:**  
> - **11-2 Full-Train RMSE 0.3974** → **11-3.1 CV RMSE 0.9205** → **11-3.2 CV RMSE 0.8882** → **11-3.3 CV RMSE 0.9045**  
> - CV RMSE는 0.92→0.89로 개선되었다가 다시 0.90으로 약간 악화됨(모델 복잡도 조정 결과)  
> - Full-Train RMSE는 0.39→0.43으로 상승(과소적합)되었지만, 최종 평가에서는 CV RMSE(≈0.90)만 확인하면 됨  
> - **대기압 모델**은 “0.9 전후” CV RMSE 수준이며, 다른 타깃 대비 비교적 낮은 오차를 유지  
> - 다음 단계:  
>   - **리프 개수, 학습률 범위**를 다시 미세 조정하거나  
>   - **외부 해양/지형 데이터**(예: 해발고도, 주변 해수면 온도) 추가 고려

---

## 4. 종합 결론

1. **습도 모델**  
   - **CV RMSE**  
     - 11-3.1: 11.2447 → 11-3.2: 11.3202 → 11-3.3: 11.1544  
     - **Optuna**로 11.32→11.15 정도 소폭 개선  
   - **Full-Train RMSE(11-2→11-3)**  
     - 6.2527 → 8.1586 → 8.8745 (전형적인 과소적합)  
   - **요약:**  
     - CV RMSE가 여전히 **≈11.2** 수준으로 매우 크고,  
     - Full-Train 지표도 6~8 사이 → 일반화 성능이 크게 떨어지는 상태  
     - **추가 피처 엔지니어링(이슬점, 풍속, 시차 lag 등)**, **모델 앙상블**이 필요

2. **기온 모델**  
   - **CV RMSE**  
     - 11-3.1: 2.9481 → 11-3.2: 2.9007 → 11-3.3: 2.8588  
     - 세 단계에 걸쳐 **2.95 → 2.86**로 점진 개선  
   - **Full-Train RMSE**  
     - 11-2: 1.0495 → 11-3.1: 0.8357 → 11-3.2: 0.7183  
     - Optuna단계에서는 값 미제공(하지만 학습 시 약 0.72 이하 기대)  
   - **요약:**  
     - Optuna 튜닝으로 CV RMSE 2.86 달성 → “기온 오차 약 2.8도”  
     - **시차 피처, 앙상블**을 더하면 2.5 이하 도전 가능

3. **대기압 모델**  
   - **CV RMSE**  
     - 11-3.1: 0.9205 → 11-3.2: 0.8882 → 11-3.3: 0.9045  
     - “11-3.2 최적 파라미터” 구간에서 CV RMSE가 가장 낮았지만, Optuna 단계에서 다시 0.90 수준으로 소폭 악화  
   - **Full-Train RMSE**  
     - 11-2: 0.3974 → 11-3.1: 0.3960 → 11-3.2: 0.4354  
   - **요약:**  
     - “대기압 오차 0.9” 수준 → 이미 충분히 낮은 편이나, CV RMSE는 0.88~0.90으로 최적화 여지 있음  
     - **추가 외부 피처(해발고도, 주변 해수면 온도 등)**를 넣어 더 낮추거나,  
     - **앙상블/스태킹**을 통해 0.8대 달성 가능

---

## 5. 보충 및 개선 방안

- **습도 모델 집중 보강**  
  1. **추가 파생 피처**  
     - “이슬점 온도(Dew Point)”, “습공차(VPD)”, “풍속/풍향”, “지면 습도(Soil Moisture)” 등  
  2. **데이터 스케일링/변환**  
     - “일사량”처럼 분포가 한쪽으로 치우친 변수에 로그 변환 시도  
  3. **다른 알고리즘 앙상블**  
     - LightGBM+CatBoost+RandomForest 평균 앙상블 → CV RMSE 10대 중반 도전
  4. **시차 lag 피처**  
     - “이전 시간대 습도(1h, 3h, 6h)”, “이전 일 습도(24h)” 등을 추가

- **기온 모델 세밀 튜닝**  
  1. **시차 lag + 이동 평균**  
     - “이전 3시간·6시간 평균 기온” 같은 변수  
  2. **앙상블/스태킹**  
     - LightGBM●XGBoost 산술 평균 또는 메타 모델 스태킹  
  3. **CV 분할 추가 검토**  
     - `n_splits=7` or `max_train_size=7200`(최근 10개월) 실험

- **대기압 모델 미세 조정**  
  1. **파라미터 범위 좁히기**  
     - `num_leaves=[15,25,35]`, `learning_rate=[0.05,0.07,0.09]`  
  2. **외부 기상 지표**  
     - “해발고도 정보”, “인접 지점 기압 측정값” 등  
  3. **앙상블 모델**  
     - LightGBM●RandomForest 평균

이상의 비교·해석을 토대로, **다음 단계**에서는 “습도 모델”을 우선적으로 강화하고, “기온/대기압 모델”도 세부 튜닝 및 앙상블을 통해 CV RMSE를 추가로 낮추는 전략을 추천합니다.  

## 습도 모델 집중 보강 결과 (1) 추가 파생 피처 & (2) 스케일링

### 1. 실험 개요
- **베이스라인 (11-3.3)**  
  - Optuna 튜닝 + 교호작용 피처  
  - 5-fold TimeSeriesSplit CV RMSE: **11.1544**

- **강화(1,2)**  
  1. **추가 파생 피처**  
     - 일사량 로그 변환(`insolation_log`)  
     - 이슬점 온도(`dew_point`)  
     - Vapor Pressure Deficit(`vpd`)  
  2. **스케일링**  
     - 훈련·검증 구간별 `StandardScaler` 적용  

### 2. 최적 파라미터 (강화 후 Optuna 결과)
```python
{
  'num_leaves': 170,
  'learning_rate': 0.0204,
  'n_estimators': 157,
  'max_depth': 12,
  'min_child_samples': 89,
  'subsample': 0.8958,
  'colsample_bytree': 0.5669
}
```
## 11-3.4 (Evaluate) 최종 가중 평균 점수 비교

| 단계                                      | 최종 가중 평균 점수 |
|-------------------------------------------|--------------------:|
| **Baseline (단일 LightGBM)**               |             **2.6939** |
| **11-1 시간 파생 변수 추가**                |              2.2055 |
| **11-2 교호작용 피처 추가**                 |              2.1810 |
| **11-3.3 하이퍼파라미터 튜닝 (단일 모델)**  |              2.6112 |
| **11-3.4 앙상블 포함 (Evaluate 결과)**      |             **2.4936** |

---

### 세부 지표 비교

| 타깃                  | 가중치 | Baseline 가중점수 | 11-1 가중점수 | 11-2 가중점수 | 11-3.3 가중점수 | 11-3.4 가중점수 |
|-----------------------|-------:|------------------:|-------------:|-------------:|---------------:|---------------:|
| **습도(%)_관측**      |   0.3  |            2.0548 |      1.6667  |      1.6458  |        2.1713  |        2.2446  |
| **기온(degC)_관측**   |   0.5  |            0.5547 |      0.4679  |      0.4652  |        0.3702  |        0.1831  |
| **대기압(mmHg)_관측** |   0.2  |            0.0844 |      0.0706  |      0.0700  |        0.0697  |        0.0658  |

- **Baseline**: 단일 LightGBM만 사용 (2.6939)  
- **11-1**: 시간 파생 변수 추가 (2.2055)  
- **11-2**: 교호작용 피처 추가 (2.1810)  
- **11-3.3**: Optuna 하이퍼파라미터 튜닝 (단일 모델) 적용 (2.6112)  
- **11-3.4**: 앙상블 모델 적용 후 평가 (Evaluate 결과) (2.4936)  

→ **11-2** 단계에서 가장 낮은 점수를 기록했으나,  
   **하이퍼파라미터 튜닝(+앙상블)** 도입 시점(11-3)에는 일시적으로 점수가 올라감을 확인.  
   최종 **Evaluate** 단계(11-3.4)에서는 **2.4936**를 달성했습니다.  
 
